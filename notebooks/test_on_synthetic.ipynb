{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import robi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def create_new_synthetic_dataset():\n",
    "    params = {\n",
    "        'n_samples': np.random.randint(2, 1000),\n",
    "        'censoring': np.round(np.random.uniform(0.1, 1.),1),\n",
    "        'nb_features': np.random.randint(2, 50),\n",
    "        'noise': np.round(np.random.uniform(0., 20.),0),\n",
    "    }\n",
    "    params['n_informative'] = np.random.randint(2, params['nb_features'])\n",
    "    params['effective_rank'] = np.random.randint(1, params['n_informative'])\n",
    "\n",
    "    params['n_samples'] = int(params['n_samples']/10)*10\n",
    "\n",
    "    df, coef = robi.utils.new_synthetic_dataset(**params)\n",
    "    return df, coef, params\n",
    "\n",
    "\n",
    "def do_trial(n_workers, n_uni_pval, n_fp_estimate, device):\n",
    "\n",
    "    df, coef, params = create_new_synthetic_dataset()\n",
    "\n",
    "    all_res = []\n",
    "    for max_corr in [0.5, 1]:\n",
    "        res, scores = robi.make_selection(df,\n",
    "                                        candidates=np.arange(len(coef)).astype('str'),\n",
    "                                        targets = {\n",
    "                                          'time': ('time', 'event'),\n",
    "                                        },\n",
    "                                        n_workers=n_workers,\n",
    "                                        n_uni_pval=n_uni_pval,\n",
    "                                        n_fp_estimate=n_fp_estimate,\n",
    "                                        verbose=False,\n",
    "                                        max_corr_cluster=max_corr,\n",
    "                                        device=device)\n",
    "\n",
    "        res['coef_sel'] = [coef[np.array(x).astype('int64')].tolist() for x in res['selected']]\n",
    "        res['actual_nfp'] = [(np.array(x)==0).sum() for x in res['coef_sel']]\n",
    "        res['actual_ntp'] = [(np.array(x)!=0).sum() for x in res['coef_sel']]\n",
    "        res = res.reset_index()\n",
    "        res = res.drop(columns=['selected', 'coef_sel', 'target'])\n",
    "\n",
    "        for k in params:\n",
    "            res[k] = params[k]\n",
    "        res['max_corr'] = max_corr\n",
    "        all_res.append(res)\n",
    "    return pd.concat(all_res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.68 GiB (GPU 0; 8.00 GiB total capacity; 13.45 GiB already allocated; 0 bytes free; 13.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[68], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m all_res \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m)):\n\u001B[1;32m----> 8\u001B[0m     all_res\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdo_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_uni_pval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_fp_estimate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     10\u001B[0m     dfr \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(all_res)\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     11\u001B[0m     dfr[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m95p_n_fp_time\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m dfr[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_FP\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, expand\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m'\u001B[39m, expand\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m, expand\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloat32\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[53], line 22\u001B[0m, in \u001B[0;36mdo_trial\u001B[1;34m(n_workers, n_uni_pval, n_fp_estimate, device)\u001B[0m\n\u001B[0;32m     20\u001B[0m all_res \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m max_corr \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m---> 22\u001B[0m     res, scores \u001B[38;5;241m=\u001B[39m \u001B[43mrobi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mcandidates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcoef\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m                                      \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mevent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mn_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mn_uni_pval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_uni_pval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mn_fp_estimate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_fp_estimate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mmax_corr_cluster\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_corr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m     res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoef_sel\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [coef[np\u001B[38;5;241m.\u001B[39marray(x)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m'\u001B[39m)]\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mselected\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m     35\u001B[0m     res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactual_nfp\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [(np\u001B[38;5;241m.\u001B[39marray(x)\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39msum() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoef_sel\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\selection.py:158\u001B[0m, in \u001B[0;36mmake_selection\u001B[1;34m(df, candidates, targets, confounders, known, strata, max_corr_cluster, n_uni_pval, n_fp_estimate, verbose, n_workers, device)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;66;03m# perform the preselection\u001B[39;00m\n\u001B[0;32m    148\u001B[0m candidates, corr_clusters, candidates_correlations \u001B[38;5;241m=\u001B[39m primary_selection(df,\n\u001B[0;32m    149\u001B[0m                                                                        candidates,\n\u001B[0;32m    150\u001B[0m                                                                        confounders,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m                                                                        verbose,\n\u001B[0;32m    156\u001B[0m                                                                        n_workers)\n\u001B[1;32m--> 158\u001B[0m scores_random \u001B[38;5;241m=\u001B[39m \u001B[43mscore_of_random\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_uni_pval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m scores \u001B[38;5;241m=\u001B[39m univariate_evaluation(df, candidates, targets, device, scores_random)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\evaluation.py:23\u001B[0m, in \u001B[0;36mscore_of_random\u001B[1;34m(df, targets, device, n_random)\u001B[0m\n\u001B[0;32m     21\u001B[0m random_cols \u001B[38;5;241m=\u001B[39m df_random\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m     22\u001B[0m df_random \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([df[\u001B[38;5;28msum\u001B[39m([\u001B[38;5;28mlist\u001B[39m(targets[x]) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m targets], [])], df_random], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompute_univariate_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_random\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_cols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\evaluation.py:15\u001B[0m, in \u001B[0;36mcompute_univariate_score\u001B[1;34m(df, random_cols, targets, device)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_univariate_score\u001B[39m(df, random_cols, targets, device):\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch_installed():\n\u001B[1;32m---> 15\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompute_univariate_score_torch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_cols\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m compute_univariate_score_npy(df, random_cols, targets)\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\evaluation_torch.py:69\u001B[0m, in \u001B[0;36mcompute_univariate_score_torch\u001B[1;34m(df, candidates, target_columns, device)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks:  \u001B[38;5;66;03m# tqdm(chunks, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}'):\u001B[39;00m\n\u001B[0;32m     68\u001B[0m     biom_values \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mas_tensor(df[chunk]\u001B[38;5;241m.\u001B[39mvalues, device\u001B[38;5;241m=\u001B[39mdevice, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\n\u001B[1;32m---> 69\u001B[0m     univ_scores \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_univariate_score_of_torch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbiom_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     70\u001B[0m     torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m     71\u001B[0m     all_univ_scores\u001B[38;5;241m.\u001B[39mappend(univ_scores)\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\evaluation_torch.py:48\u001B[0m, in \u001B[0;36mcompute_univariate_score_of_torch\u001B[1;34m(df, target_columns, chunk, biom_values)\u001B[0m\n\u001B[0;32m     45\u001B[0m biom_values_high \u001B[38;5;241m=\u001B[39m biom_values[pairs[:, \u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# compute feature's signs\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m features_cindex_by_pair \u001B[38;5;241m=\u001B[39m \u001B[43mcindex_by_pair_torch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbiom_values_high\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbiom_values_low\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     49\u001B[0m features_cindex \u001B[38;5;241m=\u001B[39m features_cindex_by_pair\u001B[38;5;241m.\u001B[39mmean(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     51\u001B[0m univ_scores_target \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(index\u001B[38;5;241m=\u001B[39mchunk)\n",
      "File \u001B[1;32m~\\Documents\\work\\articles\\article_pipeline\\robi\\robi\\evaluation_torch.py:32\u001B[0m, in \u001B[0;36mcindex_by_pair_torch\u001B[1;34m(v_high, v_low)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcindex_by_pair_torch\u001B[39m(v_high, v_low):\n\u001B[1;32m---> 32\u001B[0m     eval_comparable \u001B[38;5;241m=\u001B[39m (\u001B[43mv_high\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mv_low\u001B[49m)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m     33\u001B[0m     eval_non_comparable \u001B[38;5;241m=\u001B[39m (v_high \u001B[38;5;241m==\u001B[39m v_low)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (eval_comparable \u001B[38;5;241m+\u001B[39m (eval_non_comparable \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m))\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 1.68 GiB (GPU 0; 8.00 GiB total capacity; 13.45 GiB already allocated; 0 bytes free; 13.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "n_workers=6\n",
    "n_uni_pval=1e4\n",
    "n_fp_estimate=1000\n",
    "device = 'cuda'\n",
    "\n",
    "all_res = []\n",
    "for _ in tqdm(range(2)):\n",
    "    all_res.append(do_trial(n_workers, n_uni_pval, n_fp_estimate, device))\n",
    "\n",
    "    dfr = pd.concat(all_res).reset_index(drop=True)\n",
    "    dfr['95p_n_fp_time'] = dfr['n_FP'].str.split(' ', expand=True)[1].str.split('-', expand=True)[1].str.split(')', expand=True)[0].astype('float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "     permissiveness  n_selected            n_FP  P_only_FP  actual_nfp  \\\n0              0.01           5   0.0 (0.0-0.0)        0.0           0   \n1              0.02           5   0.0 (0.0-0.0)        0.0           0   \n2              0.03           5   0.0 (0.0-0.0)        0.0           0   \n3              0.04           5  0.1 (0.0-0.78)        0.0           0   \n4              0.05           7  0.1 (0.0-0.78)        0.0           1   \n..              ...         ...             ...        ...         ...   \n395            0.96           8  2.2 (0.0-7.78)        0.1           5   \n396            0.97           8  2.2 (0.0-7.78)        0.1           5   \n397            0.98           8  2.2 (0.0-7.78)        0.1           5   \n398            0.99           8  2.2 (0.0-7.78)        0.1           5   \n399            1.00           8  2.2 (0.0-7.78)        0.1           5   \n\n     actual_ntp  n_samples  censoring  nb_features  noise  n_informative  \\\n0             5        160        0.8           22    1.0              9   \n1             5        160        0.8           22    1.0              9   \n2             5        160        0.8           22    1.0              9   \n3             5        160        0.8           22    1.0              9   \n4             6        160        0.8           22    1.0              9   \n..          ...        ...        ...          ...    ...            ...   \n395           3        280        0.6            8    1.0              3   \n396           3        280        0.6            8    1.0              3   \n397           3        280        0.6            8    1.0              3   \n398           3        280        0.6            8    1.0              3   \n399           3        280        0.6            8    1.0              3   \n\n     effective_rank  max_corr  \n0                 2       0.5  \n1                 2       0.5  \n2                 2       0.5  \n3                 2       0.5  \n4                 2       0.5  \n..              ...       ...  \n395               1       1.0  \n396               1       1.0  \n397               1       1.0  \n398               1       1.0  \n399               1       1.0  \n\n[400 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>permissiveness</th>\n      <th>n_selected</th>\n      <th>n_FP</th>\n      <th>P_only_FP</th>\n      <th>actual_nfp</th>\n      <th>actual_ntp</th>\n      <th>n_samples</th>\n      <th>censoring</th>\n      <th>nb_features</th>\n      <th>noise</th>\n      <th>n_informative</th>\n      <th>effective_rank</th>\n      <th>max_corr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>5</td>\n      <td>0.0 (0.0-0.0)</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>160</td>\n      <td>0.8</td>\n      <td>22</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02</td>\n      <td>5</td>\n      <td>0.0 (0.0-0.0)</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>160</td>\n      <td>0.8</td>\n      <td>22</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.03</td>\n      <td>5</td>\n      <td>0.0 (0.0-0.0)</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>160</td>\n      <td>0.8</td>\n      <td>22</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.04</td>\n      <td>5</td>\n      <td>0.1 (0.0-0.78)</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>160</td>\n      <td>0.8</td>\n      <td>22</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.05</td>\n      <td>7</td>\n      <td>0.1 (0.0-0.78)</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>160</td>\n      <td>0.8</td>\n      <td>22</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>0.96</td>\n      <td>8</td>\n      <td>2.2 (0.0-7.78)</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>280</td>\n      <td>0.6</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>0.97</td>\n      <td>8</td>\n      <td>2.2 (0.0-7.78)</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>280</td>\n      <td>0.6</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>0.98</td>\n      <td>8</td>\n      <td>2.2 (0.0-7.78)</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>280</td>\n      <td>0.6</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>0.99</td>\n      <td>8</td>\n      <td>2.2 (0.0-7.78)</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>280</td>\n      <td>0.6</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>1.00</td>\n      <td>8</td>\n      <td>2.2 (0.0-7.78)</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>280</td>\n      <td>0.6</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "dfr['95p_n_fp_time'] = dfr['n_FP'].str.split(' ', expand=True)[1].str.split('-', expand=True)[1].str.split(')', expand=True)[0].astype('float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "0.375"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dfr['95p_n_fp_time'] > dfr['actual_nfp']).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
